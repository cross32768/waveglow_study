{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.0.0\n",
      "Is GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('Is GPU available:', use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "if use_gpu:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成（シンプルな正弦波＋ノイズ）\n",
    "ϵ = 0.1\n",
    "datalength = 100\n",
    "t = torch.linspace(0, 1, datalength)\n",
    "y = torch.sin(2 * np.pi * t)\n",
    "\n",
    "datasize = 500\n",
    "data_tensor = torch.zeros(datasize, datalength)\n",
    "for i in range(datasize):\n",
    "    data_tensor[i] = y.clone() + ϵ*torch.randn(t.size())\n",
    "    \n",
    "train_loader = DataLoader(data_tensor, batch_size=batchsize, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invertibity check -> ok\n",
    "class Invertible1x1Conv(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(Invertible1x1Conv, self).__init__()\n",
    "        self.conv = nn.Conv1d(num_features, num_features, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        W = torch.qr(torch.FloatTensor(num_features, num_features).normal_())[0]\n",
    "        \n",
    "        if torch.det(W) < 0:\n",
    "            W[:,0] = -1*W[:,0]\n",
    "        \n",
    "        self.conv.weight.data = W.view(num_features, num_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.conv(x)\n",
    "        log_det_jacobian = self.calculate_log_det_jacobian(x)\n",
    "        return z, log_det_jacobian\n",
    "        \n",
    "    def inverse(self, z, train_finished=False):\n",
    "        W = self.conv.weight.squeeze()\n",
    "        if train_finished:\n",
    "            if not hasattr(self, 'W_inverse'):\n",
    "                W_inverse = W.inverse()\n",
    "                self.W_inverse = W_inverse.view(*W_inverse.size(), 1)\n",
    "            x = F.conv1d(z, self.W_inverse, bias=None, stride=1, padding=0)\n",
    "        else:\n",
    "            W_inverse = W.inverse()\n",
    "            W_inverse = W_inverse.view(*W_inverse.size(), 1)\n",
    "            x = F.conv1d(z, W_inverse, bias=None, stride=1, padding=0)\n",
    "        return x\n",
    "        \n",
    "    def calculate_log_det_jacobian(self, x):\n",
    "        batch_size, group_size, n_of_groups = x.size()\n",
    "        W = self.conv.weight.squeeze()\n",
    "        log_det_jacobian = batch_size * n_of_groups * torch.logdet(W)\n",
    "        return log_det_jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(NN, self).__init__()\n",
    "        n_hidden = 64\n",
    "        self.cv1 = nn.Conv1d(n_features, n_hidden, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(n_hidden)\n",
    "        self.cv2 = nn.Conv1d(n_hidden, n_hidden, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden)\n",
    "        self.cv3 = nn.Conv1d(n_hidden, 2*n_features, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.cv3.weight.data.zero_()\n",
    "        self.cv3.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.cv1(x)))\n",
    "        out = F.relu(self.bn2(self.cv2(out)))\n",
    "        out = self.cv3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGlow(nn.Module):\n",
    "    def __init__(self, n_flows, n_group, n_early_every, n_early_size):\n",
    "        super(WaveGlow, self).__init__()\n",
    "        \n",
    "        assert(n_groups % 2 == 0)\n",
    "        self.n_flows = n_flows\n",
    "        self.n_group = n_group\n",
    "        self.n_early_every = n_early_every\n",
    "        self.n_early_size = n_early_size\n",
    "        \n",
    "        self.NN = nn.ModuleList()\n",
    "        self.convinv = nn.ModuleList()\n",
    "        \n",
    "        n_half = int(n_groups/2)\n",
    "        \n",
    "        n_remaining_channels = n_group\n",
    "        for k in range(n_flows):\n",
    "            if k % self.n_early_every == 0 and k > 0:\n",
    "                n_half = n_half - int(self.n_early_size/2)\n",
    "                n_remaining_channels = n_remaining_channels - self.n_early_size\n",
    "            self.convinv.append(Invertible1x1Conv(n_remaining_channels))\n",
    "            self.NN.append(NN(n_half))\n",
    "        self.n_remaining_channels = n_remaining_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unfold(1, self.n_group, self.n_group).permute(0, 2, 1)\n",
    "        z = []\n",
    "        log_det_jacobian = 0\n",
    "        \n",
    "        for k in range(self.n_flows):\n",
    "            if k % self.n_early_every == 0 and k > 0:\n",
    "                z.append(x[:,:self.n_early_size,:])\n",
    "                x = x[:,self.n_early_size:,:]\n",
    "            x, log_det_temp = self.convinv[k](x)\n",
    "            log_det_jacobian += log_det_temp\n",
    "            \n",
    "            n_half = int(x.size(1)/2)\n",
    "            x_0 = x[:,:n_half,:]\n",
    "            x_1 = x[:,n_half:,:]\n",
    "            \n",
    "            out = self.NN[k](x_0)\n",
    "            log_s = out[:,n_half:,:]\n",
    "            b = out[:,:n_half,:]\n",
    "            x_1 = torch.exp(log_s)*x_1 + b\n",
    "            \n",
    "            log_det_jacobian += torch.sum(log_s)\n",
    "        \n",
    "        z.append(x)\n",
    "        z = torch.cat(z, dim=1)\n",
    "        self.z_size = z.size()\n",
    "        return z, log_det_jacobian\n",
    "    \n",
    "    def infer(self, simga=1.0):\n",
    "        z = sigma * torch.cuda.FloatTensor(self.z_size[0], \n",
    "                                           self.n_remaining_channels, \n",
    "                                           self.z_size[2]).normal()\n",
    "        for k in reversed(range(self.n_flows)):\n",
    "            n_half = int(z.size(1)/2)\n",
    "            z_0 = z[:,:n_half,:]\n",
    "            z_1 = z[:,n_half:,:]\n",
    "            \n",
    "            out = self.NN[k](z_0)\n",
    "            log_s = out[:,n_half:,:]\n",
    "            b = out[:,:n_half,:]\n",
    "            z_1 = (z_1 - b) / torch.exp(log_s)\n",
    "            z = torch.cat([z_0, z_1], dim=1)\n",
    "            \n",
    "            z = self.convinv[k].inverse(z)\n",
    "            \n",
    "            if k % self.n_early_every == 0 and k > 0:\n",
    "                add_z = sigma * torch.cuda.FloatTensor(self.z_size[0], \n",
    "                                                       self.n_early_size, \n",
    "                                                       self.z_size[2]).normal_()\n",
    "                z = torch.cat([add_z, z], dim=1)\n",
    "        z = z.permute(0,2,1).contiguous().view(z.size(0), -1).data\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveGlowLoss(nn.Module):\n",
    "    def __init__(self, sigma=1.0):\n",
    "        super(WaveGlowLoss, self).__init__()\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def forward(self, model_output):\n",
    "        z, log_det_jacobian = model_output\n",
    "        batch_size, group_size, n_of_groups = z.size()\n",
    "        loss = torch.sum(z*z)/(2*self.sigma*self.sigma) - log_det_jacobian\n",
    "        \n",
    "        return loss / (batch_size*group_size*n_of_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]])\n",
      "tensor([[[ 0,  8, 16, 24, 32, 40, 48, 56],\n",
      "         [ 1,  9, 17, 25, 33, 41, 49, 57],\n",
      "         [ 2, 10, 18, 26, 34, 42, 50, 58],\n",
      "         [ 3, 11, 19, 27, 35, 43, 51, 59],\n",
      "         [ 4, 12, 20, 28, 36, 44, 52, 60],\n",
      "         [ 5, 13, 21, 29, 37, 45, 53, 61],\n",
      "         [ 6, 14, 22, 30, 38, 46, 54, 62],\n",
      "         [ 7, 15, 23, 31, 39, 47, 55, 63]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(64).view(1,-1)\n",
    "y = x.unfold(1,8,8).permute(0,2,1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.permute(0,2,1).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_flow_invertibity(net, inputs, epsilon=1e-5):\n",
    "    with torch.no_grad():    \n",
    "        recons1 = net.inverse(net.forward(inputs)[0])\n",
    "        recons2 = net.forward(net.inverse(inputs))[0]\n",
    "    \n",
    "        diff1 = torch.abs(inputs - recons1)\n",
    "        diff2 = torch.abs(inputs - recons2)\n",
    "    \n",
    "        print('forward -> inverse:', not (diff1 > epsilon).any().item())\n",
    "        print('inverse -> forward:', not (diff2 > epsilon).any().item())\n",
    "        \n",
    "    for i in range(50):\n",
    "        optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "        criterion = nn.MSELoss()\n",
    "        outputs = net(inputs)[0]\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        recons1 = net.inverse(net.forward(inputs)[0])\n",
    "        recons2 = net.forward(net.inverse(inputs))[0]\n",
    "    \n",
    "        diff1 = torch.abs(inputs - recons1)\n",
    "        diff2 = torch.abs(inputs - recons2)\n",
    "    \n",
    "        print('forward -> inverse(trained):', not (diff1 > epsilon).any().item())\n",
    "        print('inverse -> forward(trained):', not (diff2 > epsilon).any().item())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Invertible1x1Conv' object has no attribute 'param_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-2cc4e28aadc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Invertible1x1Conv' object has no attribute 'param_group'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5,5).byte().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
